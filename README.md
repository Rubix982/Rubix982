# Rubix982

## About Me

I'm a backend and infrastructure engineer learning my way through **cloud, security, and DevOps** â€” with a growing interest in how AI fits into all of it.

This GitHub is where I try things out, experiment with ideas, and take notes on what I learn. Nothing here is final â€” just projects in progress, tools I'm playing with, and thoughts I'm writing down to get better at my craft. There are learning notes, and proof-of-concept tools that reflect my curiosity across systems, security, and AI infrastructure. Many of these are early-stage â€” some are complete, some are seeds for future research.

Lately, I've been exploring:

- Building small tools in Go and Rust
- Working with orchestration systems like Temporal
- Looking into security use-cases for AI
- Writing utilities to make things more observable, testable, and explainable

That's all. Just trying to stay curious and consistent.

## Research Alignment

I maintain a basic concept project repository at [**open-concept-lab**](https://github.com/Rubix982/open-concept-lab) across security, AI, and systems that aim to show:

- âœ… My hands-on understanding of low-level mechanics
- ğŸ§  My ability to document, reason, and iterate publicly
- ğŸ“ My interest in bridging theory with practical tooling

Specifically, I wanted to more closely align myself with research over:

- Applied AI infrastructure and security
- Systems and tooling for research reproducibility
- Open-source DevSecOps and observability

## My Profile Is About ...

- ğŸ” Projects focused on **DevSecOps, observability, and security automation**
- ğŸ§  Tools that explore **AI + system design tradeoffs**, especially around reliability and compliance
- ğŸ§ª Research-inspired concepts like **reproducible evaluation**, **secure AI deployment**, and **pipeline introspection**
- ğŸ“š Thought experiments and **problem-driven brainstorming** â€” from protocol-level ideas to practical CLI tools

## Currently

Contributing to platform engineering and AI infrastructure at [Securiti.ai](https://securiti.ai) / [Securiti @ Github](https://github.com/securitiai), focused on enabling safe, intelligent use of data and AI across cloud environments.

My work spans:

- ğŸ§± Building scalable data-driven pipelines and access frameworks for cloud platforms
- âš™ï¸ Improving orchestration and system design for identity, security, and data governance workflows
- ğŸ” Supporting reliable infrastructure for secure data operations at scale

---

## Table of Contents

- [Rubix982](#rubix982)
  - [About Me](#about-me)
  - [Research Alignment](#research-alignment)
  - [My Profile Is About ...](#my-profile-is-about-)
  - [Currently](#currently)
  - [Table of Contents](#table-of-contents)
  - [Security Projects](#security-projects)
  - [Ideas \& Misc Tools](#ideas--misc-tools)
  - [Brainstorming Only](#brainstorming-only)
    - [FocusFeed](#focusfeed)
    - [PromptSnare](#promptsnare)
    - [InferGuard](#inferguard)
    - [PoisonDetect](#poisondetect)
    - [AIComplianceBot](#aicompliancebot)
    - [ModelDeployer](#modeldeployer)
    - [LLMHealth](#llmhealth)
    - [AccessHawk](#accesshawk)
    - [AirGapLLM](#airgapllm)
    - [ExplainTrail](#explaintrail)
    - [ModelAudit](#modelaudit)
    - [InferLoadBalancer](#inferloadbalancer)
    - [LLMTripwire](#llmtripwire)
    - [BatchLLM](#batchllm)
    - [ModularServe](#modularserve)
    - [SecretRadar](#secretradar)
    - [CIWatchdog](#ciwatchdog)
    - [InfraMirror](#inframirror)
    - [GhostInfra](#ghostinfra)
    - [LLMOrchestrator](#llmorchestrator)
    - [LLMSigner](#llmsigner)
    - [SecureLLMTestKit](#securellmtestkit)
    - [LLMInfraLite](#llminfralite)
    - [AISecGraph](#aisecgraph)
  - [Personal \& Configs](#personal--configs)


---

## Security Projects

> ğŸ›¡ï¸ Tools and experiments focused on cybersecurity, DevSecOps, and data visibility.

This section contains working or semi-working tools related to packet analysis, vulnerability research, network insights, and cloud security. These projects are meant to explore real-world risks, automate tasks, and improve observability across systems.

<details>
<summary>Click to expand</summary>

1. [`SecChapter`](https://github.com/Rubix982/SecChapter) â€” Long-term documentation of my journey in Cloud, Cybersecurity, and DevOps.
2. [`StructDiff`](https://github.com/Rubix982/StructDiff) â€” JSON structural diffing tool for easier inspection of data changes.
3. [`ScrapChat`](https://github.com/Rubix982/ScrapChat) â€” Tool to organize ChatGPT outputs into readable markdown sections.
4. [`ps`](https://github.com/Rubix982/ps) â€” A packet sniffer and network monitor built in Rust.
5. [`argo-apps`](https://github.com/Rubix982/argo-apps) â€” ArgoCD-based demos for distributed system orchestration.
6. [`NetPulse`](https://github.com/Rubix982/NetPulse) â€” Periodic internet speed monitor for local analysis.
7. [`VulnData`](https://github.com/Rubix982/VulnData) â€” Future dataset project for vulnerability scraping and LLM-assisted security insight.
8. [`CyberScope`](https://github.com/Rubix982/CyberScope-A-Comprehensive-Analysis-Repository) â€” Security dataset analysis based on public Kaggle sources.

</details>

---

## Ideas & Misc Tools

> ğŸ§° A mix of utilities, demos, and small projects built to test ideas or learn something new.

This is where I try things out that donâ€™t fit neatly into â€œsecurityâ€ or â€œinfraâ€ buckets â€” tooling experiments, UX ideas, or one-off playgrounds. Some are CLI tools, others are frontend visualizations or microservices.

<details>
<summary>Click to expand</summary>

1. [`Cyberflow`](https://github.com/Rubix982/Cyberflow) â€” Temporal + Go-based scanner for threat intel, enriched and cached locally.
2. [`Triage`](https://github.com/Rubix982/triage) â€” Electron-based issue triage dashboard with D3 and DuckDB.
3. [`Thoughts`](https://github.com/Rubix982/thoughts) â€” A CLI utility for fast personal note-taking.
4. [`EsMappingTests`](https://github.com/Rubix982/es-mapping-tests) â€” Elasticsearch mapping experiments.
5. [`SimpleMicroservice`](https://github.com/Rubix982/SimpleMicroservice) â€” Basic microservice starter template.
6. [`network_agent`](https://github.com/Rubix982/network_agent) â€” Local network statistics monitoring agent.
7. [`http-showcase`](https://github.com/Rubix982/http-showcase) â€” Demos of HTTP/1.1, HTTP/2, and HTTP/3 features.
8. [`go-ssl`](https://github.com/Rubix982/go-ssl) â€” Go project to inspect SSL/TLS issues.
9. [`GoRoutinesAndConcurrency`](https://github.com/Rubix982/GoRoutinesAndConcurrency) â€” Go concurrency exploration.

</details>

---

## Brainstorming Only

> âš ï¸ These are just raw, early-stage ideas â€” not finished projects.

This section is where I document security + AI + infra tools Iâ€™d like to build (or see built). Most of these are speculative, based on problems Iâ€™ve encountered, read about, or imagined from industry trends.

Some may never get past a README. Others might turn into actual code someday. Either way, this is my public lab â€” a space to think out loud and connect dots.

<details>
<summary>Click to expand</summary>

---

### FocusFeed

<details>
<summary>Click to expand</summary>

**FocusFeed** is a personal, LLM-powered command center for daily knowledge and updates.

An MCP-style system that connects LLMs (like ChatGPT or Claude) to your key information feeds â€” so you wake up to a structured, summarized digest of everything that matters.

#### Problems It Solves

- Overwhelming inboxes and news feeds
- Time wasted identifying important content
- Passive reading habits
- Loss of context and connection between information sources

#### Key Features

- ğŸ“¬ Pulls from Gmail, GitHub, Hacker News, RSS, Reddit, and arXiv
- ğŸ§  GPT/Claude summarization and context-based commentary
- ğŸ“š Highlights key terms and vocabulary
- ğŸ“† Generates digest in Markdown, email, or TUI
- ğŸ”Œ Easily extensible with new tools and endpoints
- ğŸ› ï¸ 100% self-hosted / local by design â€” no vendor lock-in

</details>

### PromptSnare

<details>
<summary>Click to expand</summary>

**PromptSnare** detects adversarial prompt injection attempts in LLM systems and enforces safe prompt structures.

#### Problems It Solves

- Prompt manipulation degrading model behavior
- Injection attacks leaking private model data
- Loss of trust in enterprise AI interfaces

#### Key Features

- ğŸ” Scans for adversarial patterns using token inspection and prompt history
- ğŸ§± Enforces safe prompt templates
- ğŸ›¡ï¸ Compatible with OpenAI, local LLMs, and prompt chaining pipelines

</details>

---

### InferGuard

<details>
<summary>Click to expand</summary>

**InferGuard** is a usage anomaly detector for LLM APIs that prevents stolen API token abuse and inference cost leaks.

#### Problems It Solves

- Unnoticed token theft and abuse
- Sudden billing spikes from inference load
- Lack of behavioral access monitoring for AI APIs

#### Key Features

- ğŸ“ˆ Tracks usage spikes and frequency patterns
- âš ï¸ Raises alerts on behavioral shifts
- ğŸ§© Hooks into billing dashboards and monitoring stacks

</details>

---

### PoisonDetect

<details>
<summary>Click to expand</summary>

**PoisonDetect** identifies tampering, bias, and poisoning in ML training datasets.

#### Problems It Solves

- Silent model poisoning in open-source data
- Training on duplicated or biased samples
- Lack of confidence in fine-tuning sources

#### Key Features

- ğŸ§  Clustering + anomaly detection on labels and samples
- ğŸ§¹ Noise filtering and scoring
- ğŸ“Š Integration with dataset pre-processing workflows

</details>

---

### AIComplianceBot

<details>
<summary>Click to expand</summary>

**AIComplianceBot** checks AI pipelines against privacy and security compliance standards like GDPR, HIPAA, and ISO 27001.

#### Problems It Solves

- AI use in regulated industries (health, finance) without auditing
- Lack of paper trails for data access and processing
- Inability to show regulators that AI systems are compliant

#### Key Features

- ğŸ§¾ Scans data flow in AI APIs and pipelines
- ğŸ” Flags PII exposure in prompts, logs, and models
- ğŸ“‹ Generates audit-ready reports

</details>

---

### ModelDeployer

<details>
<summary>Click to expand</summary>

**ModelDeployer** brings GitOps-style deployment to ML models, ensuring consistency across dev/stage/prod.

#### Problems It Solves

- Drift between model versions in different environments
- Manual copy-pasting of weights and configs
- Accidental use of outdated or incorrect models

#### Key Features

- ğŸ—ƒï¸ Hash-based versioning of weights and configs
- ğŸ” Rollbacks and deploy histories
- âš™ï¸ Works with HuggingFace, ONNX, PyTorch, etc.

</details>

---

### LLMHealth

<details>
<summary>Click to expand</summary>

**LLMHealth** offers real-time observability for LLM inference pipelines: latency, error rates, and cost insights.

#### Problems It Solves

- Inference slowdowns going undetected
- Silent memory leaks and performance regressions
- Difficulty debugging inference failures in prod

#### Key Features

- ğŸ“ˆ Prometheus/Grafana integration
- ğŸ›‘ OOM and latency spike alerts
- ğŸ§© Token-level profiling

</details>

---

### AccessHawk

<details>
<summary>Click to expand</summary>

**AccessHawk** tracks API token usage and behavior in LLM clusters to prevent insider threats and shadow access.

#### Problems It Solves

- Insider misuse of sensitive LLM features
- No visibility into who accessed what and when
- Long-lived, unused API tokens going unchecked

#### Key Features

- ğŸ•µï¸ Role-based access maps
- ğŸ“Š Heatmap of API call activity
- âš ï¸ Alerting for outlier behavior

</details>

---

### AirGapLLM

<details>
<summary>Click to expand</summary>

**AirGapLLM** is a self-hosted, air-gapped LLM deployment system with built-in access controls and observability.

#### Problems It Solves

- Regulatory restrictions on cloud AI use
- Need for full on-prem control and security
- Risk of leaking data through public APIs

#### Key Features

- ğŸ” Sandboxed GPU runners (Docker, Firecracker)
- ğŸ§¾ Logs every API call with signed hashes
- ğŸšª Access throttling and prompt whitelisting

</details>

---

### ExplainTrail

<details>
<summary>Click to expand</summary>

**ExplainTrail** creates a traceable prompt-response history with metadata to explain AI decisions.

#### Problems It Solves

- â€œBlack boxâ€ behavior in enterprise AI
- Legal/compliance challenges for explain-ability
- Lack of reproducibility in LLM-driven actions

#### Key Features

- ğŸ“š Logs prompt, context, model, and response
- ğŸ”— Metadata linking and version stamping
- âœ… Markdown or JSON-based explain-ability format

</details>

---

### ModelAudit

<details>
<summary>Click to expand</summary>

**ModelAudit** â€” Immutable logging + role-based audit trail for model access.

**Tags** - AI, Security

#### Problems It Solves

- Model access without accountability

#### Why It Hurts

- No logging = no blame if things go wrong

</details>

---

### InferLoadBalancer

<details>
<summary>Click to expand</summary>

**InferLoadBalancer** â€” Smart batching and token-limit prediction for model serving

**Tags** - AI, Infrastructure

#### Problems It Solves

- Large model deployment eats too much memory

#### Why It Hurts

- Infra teams struggle with OOM crashes

</details>

---

### LLMTripwire

<details>
<summary>Click to expand</summary>

**LLMHealth** â€” Prometheus/Grafana exporter for inference metrics.

**Tags** - AI, Infrastructure

#### Problems It Solves

- Model version mismatch across dev/stage/prod

#### Why It Hurts

- Unexpected behaviors, hard to debug

</details>

---

### BatchLLM

<details>
<summary>Click to expand</summary>

**BatchLLM** â€” Batching layer that groups inference calls based on size/priority.

**Tags** - AI, Infrastructure

#### Problems It Solves

- GPU resources are under-utilized

#### Why It Hurts

- Wasted compute, high infra costs

</details>

---

### ModularServe

<details>
<summary>Click to expand</summary>

**ModularServe** â€” Declarative YAML config for multi-modal inference APIs.

**Tags** - AI, Infrastructure

#### Problems It Solves

- Multi-modal model chaos

#### Why It Hurts

- Text, image, audio all need different runtimes

</details>

---

### SecretRadar

<details>
<summary>Click to expand</summary>

**SecretRadar** â€” Scans K8s, Vault, and envs for unmanaged secrets.

**Tags** - Security, Infrastructure

#### Problems It Solves

- No visibility into what secrets exist in your cluster

#### Why It Hurts

- Secret sprawl = breach risk.

</details>

---

### CIWatchdog

<details>
<summary>Click to expand</summary>

**CIWatchdog** - Sign and verify every CI artifact, from code to container.

**Tags** - Security, Infrastructure

#### Problems It Solves

- CI/CD pipelines are easily poisoned

#### Why It Hurts

- One bad push = widespread compromise

</details>

---

### InfraMirror

<details>
<summary>Click to expand</summary>

**InfraMirror** - Compares actual cloud state with IaC and highlights drifts

**Tags** - Security, Infrastructure

#### Problems It Solves

- IaC drift causes silent vulnerabilities

#### Why It Hurts

- Prod != Git = blind spots

</details>

---

### GhostInfra

<details>
<summary>Click to expand</summary>

**GhostInfra** - Builds a graph of cloud assets and flags ownerless nodes

**Tags** - Security, Infrastructure

#### Problems It Solves

- Shadow infra gets spun up and forgotten

#### Why It Hurts

- Unbilled/unaudited systems = easy attack targets

</details>

---

### LLMOrchestrator

<details>
<summary>Click to expand</summary>

**LLMOrchestrator** - CLI or GUI to connect models, preprocessors, and filters like a DAG

**Tags** - Platform, Utility Tooling

#### Problems It Solves

- Difficult to orchestrate multiple models/tools

</details>

---

### LLMSigner

<details>
<summary>Click to expand</summary>

**LLMSigner** - Adds cryptographic signing to every prompt-response pair

**Tags** - Platform, Utility Tooling

#### Problems It Solves

- Need signed metadata for AI actions

</details>

---

### SecureLLMTestKit

<details>
<summary>Click to expand</summary>

**SecureLLMTestKit** - Dockerized replayable attack/test pipeline with logs

**Tags** - Platform, Utility Tooling

#### Problems It Solves

- Security researchers need reproducible testbeds

</details>

---

### LLMInfraLite

<details>
<summary>Click to expand</summary>

**LLMInfraLite** - Local GPU/CPU inference deployer + observability bundle

**Tags** - Platform, Utility Tooling

#### Problems It Solves

- Developers need local AI infra that just works

</details>

---

### AISecGraph

<details>
<summary>Click to expand</summary>

**AISecGraph** - Visual dependency + threat model of entire AI pipeline

**Tags** - Platform, Utility Tooling

#### Problems It Solves

- Hard to reason about AI system security posture

</details>

---

</details>

## Personal & Configs

> ğŸ—’ï¸ Configs, notes, and personal setups that help me stay productive.

This section includes my Neovim setup, cheat sheets, reusable code snippets, and dev environment configs. Sharing them here in case theyâ€™re helpful to others â€” and to keep my own reference centralized.

<details>
<summary>Click to expand</summary>

1. [`nvim`](https://github.com/Rubix982/nvim) â€” My personal Neovim configuration.
2. [`diary`](https://github.com/Rubix982/diary) â€” Personal learnings and re-usable knowledge notes.
3. [`CodeToolBox`](https://github.com/Rubix982/CodeToolbox) â€” Handy scripts and productivity utilities.
4. [`LangLib`](https://github.com/Rubix982/LangLib) â€” Competitive programming language utility repo.
5. [`kali-linux-ctf`](https://github.com/Rubix982/kali-linux-ctf) â€” Vagrant + Kali setup for security challenges.
6. [`LeetCode`](https://github.com/Rubix982/LeetCode) â€” My solutions to Leetcode problems.

</details>
