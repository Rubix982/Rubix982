# Rubix982

## About Me

I'm a backend and infrastructure engineer learning my way through **cloud, security, and DevOps** — with a growing interest in how AI fits into all of it.

This GitHub is where I try things out, experiment with ideas, and take notes on what I learn. Nothing here is final — just projects in progress, tools I'm playing with, and thoughts I'm writing down to get better at my craft. There are learning notes, and proof-of-concept tools that reflect my curiosity across systems, security, and AI infrastructure. Many of these are early-stage — some are complete, some are seeds for future research.

Lately, I've been exploring:

- Building small tools in Go and Rust
- Working with orchestration systems like Temporal
- Looking into security use-cases for AI
- Writing utilities to make things more observable, testable, and explainable

That's all. Just trying to stay curious and consistent.

## Research Alignment

I maintain a basic concept project repository at [**open-concept-lab**](https://github.com/Rubix982/open-concept-lab) across security, AI, and systems that aim to show:

- ✅ My hands-on understanding of low-level mechanics
- 🧠 My ability to document, reason, and iterate publicly
- 📎 My interest in bridging theory with practical tooling

Specifically, I wanted to more closely align myself with research over:

- Applied AI infrastructure and security
- Systems and tooling for research reproducibility
- Open-source DevSecOps and observability

## My Profile Is About ...

- 🔐 Projects focused on **DevSecOps, observability, and security automation**
- 🧠 Tools that explore **AI + system design tradeoffs**, especially around reliability and compliance
- 🧪 Research-inspired concepts like **reproducible evaluation**, **secure AI deployment**, and **pipeline introspection**
- 📚 Thought experiments and **problem-driven brainstorming** — from protocol-level ideas to practical CLI tools

## Currently

Contributing to platform engineering and AI infrastructure at [Securiti.ai](https://securiti.ai) / [Securiti @ Github](https://github.com/securitiai), focused on enabling safe, intelligent use of data and AI across cloud environments.

My work spans:

- 🧱 Building scalable data-driven pipelines and access frameworks for cloud platforms
- ⚙️ Improving orchestration and system design for identity, security, and data governance workflows
- 🔐 Supporting reliable infrastructure for secure data operations at scale

---

## Table of Contents

- [Rubix982](#rubix982)
  - [About Me](#about-me)
  - [Research Alignment](#research-alignment)
  - [My Profile Is About ...](#my-profile-is-about-)
  - [Currently](#currently)
  - [Table of Contents](#table-of-contents)
  - [Security Projects](#security-projects)
  - [Ideas \& Misc Tools](#ideas--misc-tools)
  - [Brainstorming Only](#brainstorming-only)
    - [FocusFeed](#focusfeed)
    - [PromptSnare](#promptsnare)
    - [InferGuard](#inferguard)
    - [PoisonDetect](#poisondetect)
    - [AIComplianceBot](#aicompliancebot)
    - [ModelDeployer](#modeldeployer)
    - [LLMHealth](#llmhealth)
    - [AccessHawk](#accesshawk)
    - [AirGapLLM](#airgapllm)
    - [ExplainTrail](#explaintrail)
    - [ModelAudit](#modelaudit)
    - [InferLoadBalancer](#inferloadbalancer)
    - [LLMTripwire](#llmtripwire)
    - [BatchLLM](#batchllm)
    - [ModularServe](#modularserve)
    - [SecretRadar](#secretradar)
    - [CIWatchdog](#ciwatchdog)
    - [InfraMirror](#inframirror)
    - [GhostInfra](#ghostinfra)
    - [LLMOrchestrator](#llmorchestrator)
    - [LLMSigner](#llmsigner)
    - [SecureLLMTestKit](#securellmtestkit)
    - [LLMInfraLite](#llminfralite)
    - [AISecGraph](#aisecgraph)
  - [Personal \& Configs](#personal--configs)


---

## Security Projects

> 🛡️ Tools and experiments focused on cybersecurity, DevSecOps, and data visibility.

This section contains working or semi-working tools related to packet analysis, vulnerability research, network insights, and cloud security. These projects are meant to explore real-world risks, automate tasks, and improve observability across systems.

<details>
<summary>Click to expand</summary>

1. [`SecChapter`](https://github.com/Rubix982/SecChapter) — Long-term documentation of my journey in Cloud, Cybersecurity, and DevOps.
2. [`StructDiff`](https://github.com/Rubix982/StructDiff) — JSON structural diffing tool for easier inspection of data changes.
3. [`ScrapChat`](https://github.com/Rubix982/ScrapChat) — Tool to organize ChatGPT outputs into readable markdown sections.
4. [`ps`](https://github.com/Rubix982/ps) — A packet sniffer and network monitor built in Rust.
5. [`argo-apps`](https://github.com/Rubix982/argo-apps) — ArgoCD-based demos for distributed system orchestration.
6. [`NetPulse`](https://github.com/Rubix982/NetPulse) — Periodic internet speed monitor for local analysis.
7. [`VulnData`](https://github.com/Rubix982/VulnData) — Future dataset project for vulnerability scraping and LLM-assisted security insight.
8. [`CyberScope`](https://github.com/Rubix982/CyberScope-A-Comprehensive-Analysis-Repository) — Security dataset analysis based on public Kaggle sources.

</details>

---

## Ideas & Misc Tools

> 🧰 A mix of utilities, demos, and small projects built to test ideas or learn something new.

This is where I try things out that don’t fit neatly into “security” or “infra” buckets — tooling experiments, UX ideas, or one-off playgrounds. Some are CLI tools, others are frontend visualizations or microservices.

<details>
<summary>Click to expand</summary>

1. [`Cyberflow`](https://github.com/Rubix982/Cyberflow) — Temporal + Go-based scanner for threat intel, enriched and cached locally.
2. [`Triage`](https://github.com/Rubix982/triage) — Electron-based issue triage dashboard with D3 and DuckDB.
3. [`Thoughts`](https://github.com/Rubix982/thoughts) — A CLI utility for fast personal note-taking.
4. [`EsMappingTests`](https://github.com/Rubix982/es-mapping-tests) — Elasticsearch mapping experiments.
5. [`SimpleMicroservice`](https://github.com/Rubix982/SimpleMicroservice) — Basic microservice starter template.
6. [`network_agent`](https://github.com/Rubix982/network_agent) — Local network statistics monitoring agent.
7. [`http-showcase`](https://github.com/Rubix982/http-showcase) — Demos of HTTP/1.1, HTTP/2, and HTTP/3 features.
8. [`go-ssl`](https://github.com/Rubix982/go-ssl) — Go project to inspect SSL/TLS issues.
9. [`GoRoutinesAndConcurrency`](https://github.com/Rubix982/GoRoutinesAndConcurrency) — Go concurrency exploration.

</details>

---

## Brainstorming Only

> ⚠️ These are just raw, early-stage ideas — not finished projects.

This section is where I document security + AI + infra tools I’d like to build (or see built). Most of these are speculative, based on problems I’ve encountered, read about, or imagined from industry trends.

Some may never get past a README. Others might turn into actual code someday. Either way, this is my public lab — a space to think out loud and connect dots.

<details>
<summary>Click to expand</summary>

---

### FocusFeed

<details>
<summary>Click to expand</summary>

**FocusFeed** is a personal, LLM-powered command center for daily knowledge and updates.

An MCP-style system that connects LLMs (like ChatGPT or Claude) to your key information feeds — so you wake up to a structured, summarized digest of everything that matters.

#### Problems It Solves

- Overwhelming inboxes and news feeds
- Time wasted identifying important content
- Passive reading habits
- Loss of context and connection between information sources

#### Key Features

- 📬 Pulls from Gmail, GitHub, Hacker News, RSS, Reddit, and arXiv
- 🧠 GPT/Claude summarization and context-based commentary
- 📚 Highlights key terms and vocabulary
- 📆 Generates digest in Markdown, email, or TUI
- 🔌 Easily extensible with new tools and endpoints
- 🛠️ 100% self-hosted / local by design — no vendor lock-in

</details>

### PromptSnare

<details>
<summary>Click to expand</summary>

**PromptSnare** detects adversarial prompt injection attempts in LLM systems and enforces safe prompt structures.

#### Problems It Solves

- Prompt manipulation degrading model behavior
- Injection attacks leaking private model data
- Loss of trust in enterprise AI interfaces

#### Key Features

- 🔍 Scans for adversarial patterns using token inspection and prompt history
- 🧱 Enforces safe prompt templates
- 🛡️ Compatible with OpenAI, local LLMs, and prompt chaining pipelines

</details>

---

### InferGuard

<details>
<summary>Click to expand</summary>

**InferGuard** is a usage anomaly detector for LLM APIs that prevents stolen API token abuse and inference cost leaks.

#### Problems It Solves

- Unnoticed token theft and abuse
- Sudden billing spikes from inference load
- Lack of behavioral access monitoring for AI APIs

#### Key Features

- 📈 Tracks usage spikes and frequency patterns
- ⚠️ Raises alerts on behavioral shifts
- 🧩 Hooks into billing dashboards and monitoring stacks

</details>

---

### PoisonDetect

<details>
<summary>Click to expand</summary>

**PoisonDetect** identifies tampering, bias, and poisoning in ML training datasets.

#### Problems It Solves

- Silent model poisoning in open-source data
- Training on duplicated or biased samples
- Lack of confidence in fine-tuning sources

#### Key Features

- 🧠 Clustering + anomaly detection on labels and samples
- 🧹 Noise filtering and scoring
- 📊 Integration with dataset pre-processing workflows

</details>

---

### AIComplianceBot

<details>
<summary>Click to expand</summary>

**AIComplianceBot** checks AI pipelines against privacy and security compliance standards like GDPR, HIPAA, and ISO 27001.

#### Problems It Solves

- AI use in regulated industries (health, finance) without auditing
- Lack of paper trails for data access and processing
- Inability to show regulators that AI systems are compliant

#### Key Features

- 🧾 Scans data flow in AI APIs and pipelines
- 🔍 Flags PII exposure in prompts, logs, and models
- 📋 Generates audit-ready reports

</details>

---

### ModelDeployer

<details>
<summary>Click to expand</summary>

**ModelDeployer** brings GitOps-style deployment to ML models, ensuring consistency across dev/stage/prod.

#### Problems It Solves

- Drift between model versions in different environments
- Manual copy-pasting of weights and configs
- Accidental use of outdated or incorrect models

#### Key Features

- 🗃️ Hash-based versioning of weights and configs
- 🔁 Rollbacks and deploy histories
- ⚙️ Works with HuggingFace, ONNX, PyTorch, etc.

</details>

---

### LLMHealth

<details>
<summary>Click to expand</summary>

**LLMHealth** offers real-time observability for LLM inference pipelines: latency, error rates, and cost insights.

#### Problems It Solves

- Inference slowdowns going undetected
- Silent memory leaks and performance regressions
- Difficulty debugging inference failures in prod

#### Key Features

- 📈 Prometheus/Grafana integration
- 🛑 OOM and latency spike alerts
- 🧩 Token-level profiling

</details>

---

### AccessHawk

<details>
<summary>Click to expand</summary>

**AccessHawk** tracks API token usage and behavior in LLM clusters to prevent insider threats and shadow access.

#### Problems It Solves

- Insider misuse of sensitive LLM features
- No visibility into who accessed what and when
- Long-lived, unused API tokens going unchecked

#### Key Features

- 🕵️ Role-based access maps
- 📊 Heatmap of API call activity
- ⚠️ Alerting for outlier behavior

</details>

---

### AirGapLLM

<details>
<summary>Click to expand</summary>

**AirGapLLM** is a self-hosted, air-gapped LLM deployment system with built-in access controls and observability.

#### Problems It Solves

- Regulatory restrictions on cloud AI use
- Need for full on-prem control and security
- Risk of leaking data through public APIs

#### Key Features

- 🔐 Sandboxed GPU runners (Docker, Firecracker)
- 🧾 Logs every API call with signed hashes
- 🚪 Access throttling and prompt whitelisting

</details>

---

### ExplainTrail

<details>
<summary>Click to expand</summary>

**ExplainTrail** creates a traceable prompt-response history with metadata to explain AI decisions.

#### Problems It Solves

- “Black box” behavior in enterprise AI
- Legal/compliance challenges for explain-ability
- Lack of reproducibility in LLM-driven actions

#### Key Features

- 📚 Logs prompt, context, model, and response
- 🔗 Metadata linking and version stamping
- ✅ Markdown or JSON-based explain-ability format

</details>

---

### ModelAudit

<details>
<summary>Click to expand</summary>

**ModelAudit** — Immutable logging + role-based audit trail for model access.

**Tags** - AI, Security

#### Problems It Solves

- Model access without accountability

#### Why It Hurts

- No logging = no blame if things go wrong

</details>

---

### InferLoadBalancer

<details>
<summary>Click to expand</summary>

**InferLoadBalancer** — Smart batching and token-limit prediction for model serving

**Tags** - AI, Infrastructure

#### Problems It Solves

- Large model deployment eats too much memory

#### Why It Hurts

- Infra teams struggle with OOM crashes

</details>

---

### LLMTripwire

<details>
<summary>Click to expand</summary>

**LLMHealth** — Prometheus/Grafana exporter for inference metrics.

**Tags** - AI, Infrastructure

#### Problems It Solves

- Model version mismatch across dev/stage/prod

#### Why It Hurts

- Unexpected behaviors, hard to debug

</details>

---

### BatchLLM

<details>
<summary>Click to expand</summary>

**BatchLLM** — Batching layer that groups inference calls based on size/priority.

**Tags** - AI, Infrastructure

#### Problems It Solves

- GPU resources are under-utilized

#### Why It Hurts

- Wasted compute, high infra costs

</details>

---

### ModularServe

<details>
<summary>Click to expand</summary>

**ModularServe** — Declarative YAML config for multi-modal inference APIs.

**Tags** - AI, Infrastructure

#### Problems It Solves

- Multi-modal model chaos

#### Why It Hurts

- Text, image, audio all need different runtimes

</details>

---

### SecretRadar

<details>
<summary>Click to expand</summary>

**SecretRadar** — Scans K8s, Vault, and envs for unmanaged secrets.

**Tags** - Security, Infrastructure

#### Problems It Solves

- No visibility into what secrets exist in your cluster

#### Why It Hurts

- Secret sprawl = breach risk.

</details>

---

### CIWatchdog

<details>
<summary>Click to expand</summary>

**CIWatchdog** - Sign and verify every CI artifact, from code to container.

**Tags** - Security, Infrastructure

#### Problems It Solves

- CI/CD pipelines are easily poisoned

#### Why It Hurts

- One bad push = widespread compromise

</details>

---

### InfraMirror

<details>
<summary>Click to expand</summary>

**InfraMirror** - Compares actual cloud state with IaC and highlights drifts

**Tags** - Security, Infrastructure

#### Problems It Solves

- IaC drift causes silent vulnerabilities

#### Why It Hurts

- Prod != Git = blind spots

</details>

---

### GhostInfra

<details>
<summary>Click to expand</summary>

**GhostInfra** - Builds a graph of cloud assets and flags ownerless nodes

**Tags** - Security, Infrastructure

#### Problems It Solves

- Shadow infra gets spun up and forgotten

#### Why It Hurts

- Unbilled/unaudited systems = easy attack targets

</details>

---

### LLMOrchestrator

<details>
<summary>Click to expand</summary>

**LLMOrchestrator** - CLI or GUI to connect models, preprocessors, and filters like a DAG

**Tags** - Platform, Utility Tooling

#### Problems It Solves

- Difficult to orchestrate multiple models/tools

</details>

---

### LLMSigner

<details>
<summary>Click to expand</summary>

**LLMSigner** - Adds cryptographic signing to every prompt-response pair

**Tags** - Platform, Utility Tooling

#### Problems It Solves

- Need signed metadata for AI actions

</details>

---

### SecureLLMTestKit

<details>
<summary>Click to expand</summary>

**SecureLLMTestKit** - Dockerized replayable attack/test pipeline with logs

**Tags** - Platform, Utility Tooling

#### Problems It Solves

- Security researchers need reproducible testbeds

</details>

---

### LLMInfraLite

<details>
<summary>Click to expand</summary>

**LLMInfraLite** - Local GPU/CPU inference deployer + observability bundle

**Tags** - Platform, Utility Tooling

#### Problems It Solves

- Developers need local AI infra that just works

</details>

---

### AISecGraph

<details>
<summary>Click to expand</summary>

**AISecGraph** - Visual dependency + threat model of entire AI pipeline

**Tags** - Platform, Utility Tooling

#### Problems It Solves

- Hard to reason about AI system security posture

</details>

---

</details>

## Personal & Configs

> 🗒️ Configs, notes, and personal setups that help me stay productive.

This section includes my Neovim setup, cheat sheets, reusable code snippets, and dev environment configs. Sharing them here in case they’re helpful to others — and to keep my own reference centralized.

<details>
<summary>Click to expand</summary>

1. [`nvim`](https://github.com/Rubix982/nvim) — My personal Neovim configuration.
2. [`diary`](https://github.com/Rubix982/diary) — Personal learnings and re-usable knowledge notes.
3. [`CodeToolBox`](https://github.com/Rubix982/CodeToolbox) — Handy scripts and productivity utilities.
4. [`LangLib`](https://github.com/Rubix982/LangLib) — Competitive programming language utility repo.
5. [`kali-linux-ctf`](https://github.com/Rubix982/kali-linux-ctf) — Vagrant + Kali setup for security challenges.
6. [`LeetCode`](https://github.com/Rubix982/LeetCode) — My solutions to Leetcode problems.

</details>
